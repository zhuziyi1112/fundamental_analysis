{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: finnhub-python in /opt/anaconda3/lib/python3.11/site-packages (2.4.21)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from finnhub-python) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->finnhub-python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->finnhub-python) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->finnhub-python) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.22.0->finnhub-python) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install finnhub-python\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/richazhu/Desktop/MyValues\n",
      "Missing tickers: ['^IXIC', '^VIX', '^TNX', '^IRX', 'TLT', 'TMF', 'SHY', 'EDV', 'ZROZ', 'GOVT', 'VXX', 'UVXY', 'MTUM', 'SPY', 'QQQ', 'QQQM', 'VOOG', 'VGT', 'XLU', 'GLD', 'IAU', 'PHYS', 'GDX', 'SLV', 'IAU']\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()  # Get the current working directory\n",
    "print(current_directory)  # Outputs the current directory\n",
    "subdirectory = 'manual_inputs'  # This is your target subfolder\n",
    "file_name = 'all_tickers.txt'  # Name of the file to save\n",
    "file_path = os.path.join(current_directory, subdirectory, file_name)  # Full path for the file\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    all_tickers = file.read().splitlines()\n",
    "\n",
    "# with open('all_tickers.txt', 'r') as file:\n",
    "#     all_tickers = file.read().splitlines()\n",
    "    \n",
    "# Market Indices\n",
    "tickers = [\n",
    "    '^IXIC',\n",
    "    '^VIX',  # CBOE Volatility Index\n",
    "    '^TNX',  # 10-Year Treasury Note Yield\n",
    "    '^IRX',  # 13-Week Treasury Bill Yield\n",
    "]\n",
    "\n",
    "# Bonds and Fixed Income ETFs\n",
    "tickers += [\n",
    "    'TLT',   # iShares 20+ Year Treasury Bond ETF\n",
    "    'TMF',   # Direxion Daily 20-Year Treasury Bull 3X Shares\n",
    "    'SHY',   # iShares 1-3 Year Treasury Bond ETF\n",
    "    'EDV',   # Vanguard Extended Duration Treasury ETF\n",
    "    'ZROZ',  # PIMCO 25+ Year Zero Coupon U.S. Treasury Index ETF\n",
    "    'GOVT',  # Vanguard U.S. Government Bond ETF\n",
    "]\n",
    "\n",
    "# Volatility and Inverse ETFs\n",
    "tickers += [\n",
    "    'VXX',   # iPath Series B S&P 500 VIX Short-Term Futures ETN\n",
    "    'UVXY',  # ProShares Ultra VIX Short-Term Futures ETF\n",
    "]\n",
    "\n",
    "# Growth and Value ETFs\n",
    "tickers += [\n",
    "    'MTUM',  # iShares Edge MSCI USA Momentum Factor ETF\n",
    "    'SPY',   # SPDR S&P 500 ETF Trust\n",
    "    'QQQ',   # Invesco QQQ Trust (Nasdaq 100)\n",
    "    'QQQM',  # Invesco NASDAQ 100 ETF (mini)\n",
    "    'VOOG',  # Vanguard S&P 500 Growth ETF\n",
    "    'VGT',   # Vanguard Information Technology ETF\n",
    "    'XLU',   # Utilities Select Sector SPDR Fund\n",
    "]\n",
    "\n",
    "# Large-Cap Stocks\n",
    "tickers += [\n",
    "    'GOOG',  # Alphabet Inc. (Class C)\n",
    "    'AVGO',  # Broadcom Inc.\n",
    "    'AMZN',  # Amazon.com, Inc.\n",
    "    'NVDA',  # NVIDIA Corporation\n",
    "    'MSFT',  # Microsoft Corporation\n",
    "    'DIS',   # The Walt Disney Company\n",
    "    'AAPL',  # Apple Inc.\n",
    "    'WMT',   # Walmart Inc.\n",
    "    'META',  # Meta Platforms, Inc. (formerly Facebook)\n",
    "    'COST',  # Costco Wholesale Corporation\n",
    "]\n",
    "\n",
    "# Precious Metals\n",
    "tickers += [\n",
    "    'GLD',   # SPDR Gold Shares\n",
    "    'IAU',   # iShares Gold Trust\n",
    "    'PHYS',  # Sprott Physical Gold Trust\n",
    "    'GDX',   # VanEck Vectors Gold Miners ETF\n",
    "    'SLV',   # iShares Silver Trust\n",
    "    'IAU',   # iShares Gold Trust (duplicate)\n",
    "]\n",
    "\n",
    "# Small and Mid-Cap Stocks / Growth Companies\n",
    "tickers += [\n",
    "    'SFM',   # Sprouts Farmers Market, Inc.\n",
    "    'PLTR',  # Palantir Technologies Inc.\n",
    "    'QUBT',  # Quantum Computing Inc.\n",
    "    'IONQ',  # IonQ, Inc. (quantum computing)\n",
    "    'APLD',  # Applied Digital Corporation\n",
    "    'LMND',  # Lemonade, Inc.\n",
    "    'VRT',   # Vertiv Holdings Co.\n",
    "    'RKLB',  # Rocket Lab USA, Inc.\n",
    "    'AFRM',  # Affirm Holdings, Inc.\n",
    "    'FLR',   # Fluor Corporation\n",
    "    'ESOA',  # Eos Energy Enterprises, Inc.\n",
    "    'BKNG',  # Booking Holdings Inc.\n",
    "    'HQY',   # HealthEquity, Inc.\n",
    "    'NU',    # Nu Holdings Ltd.\n",
    "    'VNO',   # Vornado Realty Trust\n",
    "    'MP',    # MP Materials Corp.\n",
    "    'SMR',   # SM Energy Company\n",
    "    'IDCC',  # InterDigital, Inc.\n",
    "    'RVMD',  # Reviva Pharmaceuticals Holdings, Inc.\n",
    "    'DHI',   # D.R. Horton, Inc.\n",
    "    'PANW',  # Palo Alto Networks, Inc.\n",
    "    'DASH',  # DoorDash, Inc.\n",
    "    'CHWY',  # Chewy, Inc.\n",
    "    'WPM',   # Wheaton Precious Metals Corp.\n",
    "    'SE',    # Sea Limited\n",
    "     'T',    # AT&T Inc.\n",
    "    'LMT',   # Lockheed Martin Corporation\n",
    "    'TKO',   # Take-Two Interactive Software, Inc.\n",
    "    'LNTH',  # Lantheus Holdings, Inc.\n",
    "    'FICO',  # Fair Isaac Corporation (FICO)\n",
    "]\n",
    "\n",
    "# Chemicals and Energy\n",
    "tickers += [\n",
    "    'CL',    # Continental Resources, Inc.\n",
    "    'NEE',   # NextEra Energy, Inc.\n",
    "    'CCJ',   # Cameco Corporation\n",
    "    'GEVO',  # Gevo, Inc.\n",
    "]\n",
    "\n",
    "# Check which tickers in your tickers list are not in all_tickers\n",
    "missing_tickers = [ticker for ticker in tickers if ticker not in all_tickers]\n",
    "\n",
    "# Print results\n",
    "if not missing_tickers:\n",
    "    print(\"All tickers are included in all_tickers.\")\n",
    "else:\n",
    "    print(\"Missing tickers:\", missing_tickers)\n",
    "    \n",
    "all_tickers += missing_tickers\n",
    "all_tickers.sort()\n",
    "\n",
    "# tickers = all_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Indicators - High Momentum Factor / High Quality Score (HMHQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Initialize a dictionary to store results for each ticker\n",
    "results = {}\n",
    "\n",
    "# Define a target return (for instance, the risk-free rate)\n",
    "target_return = 0.0  # Adjust this as needed\n",
    "rolling_window = 20   # Define the window size for rolling calculations\n",
    "\n",
    "# Define the benchmark\n",
    "benchmark_ticker = 'SPY'\n",
    "\n",
    "# ** Data Processing Loop for Each Ticker **\n",
    "for ticker in tickers:\n",
    "    # ** 0A. Data Downloading Section **\n",
    "    try:\n",
    "        data = yf.download(ticker, start=(datetime.now() - timedelta(days=2*365)).strftime(\"%Y-%m-%d\"), end=datetime.now().strftime(\"%Y-%m-%d\"), interval=\"1d\")\n",
    "\n",
    "        # Check if the data is empty\n",
    "        if data.empty:\n",
    "            print(f\"No data found for {ticker}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Add benchmark data for Beta calculation\n",
    "        if ticker == benchmark_ticker:\n",
    "            benchmark_data = data['Close']\n",
    "            continue  # Skip the rest for the benchmark itself\n",
    "\n",
    "        # ** 0. Moving Averages Section **\n",
    "        data['3_SMA'] = data['Close'].rolling(window=3).mean()\n",
    "        data['5_SMA'] = data['Close'].rolling(window=5).mean()\n",
    "        data['20_SMA'] = data['Close'].rolling(window=20).mean()\n",
    "        data['50_SMA'] = data['Close'].rolling(window=50).mean()\n",
    "        data['90_SMA'] = data['Close'].rolling(window=90).mean()\n",
    "        data['180_SMA'] = data['Close'].rolling(window=180).mean()\n",
    "        data['360_SMA'] = data['Close'].rolling(window=360).mean()\n",
    "   \n",
    "        # ** 0. Price Change Calculations Section **\n",
    "        data['Price_Change%'] = data['Close'].pct_change() * 100 \n",
    "        data['Cumulative_Returns'] = (1 + data['Price_Change%'] / 100).cumprod()\n",
    "             \n",
    "        # ** 1. Market Trend Section - when 3_SMA > 5_SMA **\n",
    "        data['Market_Trend'] = 0\n",
    "        data.loc[data['3_SMA'] > data['5_SMA'], 'Market_Trend'] = 1\n",
    "        data.loc[data['3_SMA'] < data['5_SMA'], 'Market_Trend'] = -1\n",
    "\n",
    "        # ** 2. Rolling Maximum Drawdown Calculation Section **\n",
    "        data['Rolling_Peak'] = data['Cumulative_Returns'].cummax()\n",
    "        data['Rolling_Drawdown'] = (data['Cumulative_Returns'] - data['Rolling_Peak']) / data['Rolling_Peak']\n",
    "\n",
    "        # ** 3. Cumulative Change Calculation Section using vectorized operations **\n",
    "        current_trend_shifted = data['Market_Trend'].shift(1)\n",
    "        current_base_price = data['Close'].shift(1).where(current_trend_shifted != data['Market_Trend']).ffill()\n",
    "        data['Cumulative_Change%'] = ((data['Close'] - current_base_price) / current_base_price) * 100\n",
    "        data['Over_10%_in_90_days'] = data['Cumulative_Change%'].rolling(window=90, min_periods=1).max() > 10\n",
    "        data['Over_10%_in_90_days'] = data['Over_10%_in_90_days'].astype(int)\n",
    "\n",
    "        # ** 4. Rolling Up/Down Ratio Calculation **\n",
    "        data['Up_Day'] = data['Price_Change%'].apply(lambda x: x if x > 0 else 0)\n",
    "        data['Down_Day'] = data['Price_Change%'].apply(lambda x: -x if x < 0 else 0)\n",
    "        data['Rolling_Up_Down_Ratio'] = data['Up_Day'].rolling(window=rolling_window).mean() / data['Down_Day'].rolling(window=rolling_window).mean()\n",
    "        \n",
    "        # ** 5. Rolling True Strength Index (TSI) Calculation **\n",
    "        data['Smooth_Price_Change'] = data['Price_Change%'].ewm(span=25, adjust=False).mean()  # Fast TSI\n",
    "        data['Smooth_Price_Change_Slow'] = data['Price_Change%'].ewm(span=13, adjust=False).mean()  # Slow TSI\n",
    "        data['TSI'] = 100 * (data['Smooth_Price_Change'] - data['Smooth_Price_Change_Slow']) / data['Smooth_Price_Change_Slow']\n",
    "        data['Rolling_TSI'] = data['TSI'].rolling(window=rolling_window).mean()\n",
    "\n",
    "        # ** 6. Rolling Volatility Calculation **\n",
    "        data['Rolling_Volatility'] = data['Price_Change%'].rolling(window=rolling_window).std()\n",
    "\n",
    "        # ** 7. Rolling Maximum Consecutive Up Days Calculation **\n",
    "        data['Consecutive_Up_Days'] = (data['Price_Change%'] > 0).astype(int)\n",
    "        data['Rolling_Consecutive_Up_Days'] = data['Consecutive_Up_Days'].groupby((data['Consecutive_Up_Days'] != data['Consecutive_Up_Days'].shift()).cumsum()).cumsum()\n",
    "        \n",
    "        # ** 8. Max Rolling Consecutive Up Days in a 20-day Window **\n",
    "        consecutive_counts = data['Consecutive_Up_Days'].rolling(window=rolling_window).apply(\n",
    "            lambda x: (x != 0).astype(int).groupby((x != 0).ne((x.shift())).cumsum()).cumsum().max(),\n",
    "            raw=False\n",
    "        )\n",
    "        data['Max_Rolling_Consecutive_Up_Days'] = consecutive_counts\n",
    "        \n",
    "        consecutive_counts = data['Consecutive_Up_Days'].rolling(window=90).apply(\n",
    "            lambda x: (x != 0).astype(int).groupby((x != 0).ne((x.shift())).cumsum()).cumsum().max(),\n",
    "            raw=False\n",
    "        )\n",
    "        data['Max_SemiAnnual_Consecutive_Up_Days'] = consecutive_counts\n",
    "        data['Potential_Up_Days'] = data['Max_SemiAnnual_Consecutive_Up_Days']-data['Consecutive_Up_Days']\n",
    "\n",
    "        # ** 9. RSI Calculation (Relative Strength Index) **\n",
    "        delta = data['Close'].diff(1)\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=rolling_window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=rolling_window).mean()\n",
    "        rs = gain / loss\n",
    "        data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        # ** 10. Momentum Calculation **\n",
    "        data['Momentum'] = data['Close'].diff(rolling_window)\n",
    "\n",
    "        # ** 11. ATR Calculation (Average True Range) **\n",
    "        data['High_Low'] = data['High'] - data['Low']\n",
    "        data['High_Close'] = (data['High'] - data['Close'].shift(1)).abs()\n",
    "        data['Low_Close'] = (data['Low'] - data['Close'].shift(1)).abs()\n",
    "        data['True_Range'] = data[['High_Low', 'High_Close', 'Low_Close']].max(axis=1)\n",
    "        data['ATR'] = data['True_Range'].rolling(window=rolling_window).mean()\n",
    "\n",
    "        # ** 12. Beta Calculation **\n",
    "        if 'benchmark_data' in locals():\n",
    "            returns = data['Close'].pct_change()\n",
    "            benchmark_returns = benchmark_data.pct_change()\n",
    "            covariance = returns.rolling(window=rolling_window).cov(benchmark_returns)\n",
    "            variance = benchmark_returns.rolling(window=rolling_window).var()\n",
    "\n",
    "            data['Beta'] = covariance / variance\n",
    "\n",
    "        # ** 13. Alpha Calculation **\n",
    "        if 'benchmark_data' in locals():\n",
    "            average_benchmark_return = benchmark_data.pct_change().rolling(window=rolling_window).mean()\n",
    "            data['Alpha'] = (data['Price_Change%'].rolling(window=rolling_window).mean() - (data['Beta'] * average_benchmark_return)).fillna(0)\n",
    "\n",
    "        # ** 14. Preparing the Trend Indicator DataFrame **\n",
    "        trend_indicator = data[['Close', \n",
    "                                'Price_Change%', \n",
    "                                'Market_Trend', \n",
    "                                'Cumulative_Change%', \n",
    "                                'Over_10%_in_90_days',\n",
    "                                'Rolling_Drawdown', \n",
    "                                'Rolling_Up_Down_Ratio', \n",
    "                                'Rolling_TSI', \n",
    "                                'Rolling_Volatility', \n",
    "                                'Rolling_Consecutive_Up_Days', \n",
    "                                'Max_Rolling_Consecutive_Up_Days', \n",
    "                                'Max_SemiAnnual_Consecutive_Up_Days',\n",
    "                                'Potential_Up_Days',\n",
    "                                'RSI', \n",
    "                                'Momentum',\n",
    "                                'ATR']].dropna()\n",
    "\n",
    "        # Conditionally adding Alpha and Beta if they exist in the DataFrame\n",
    "        trend_columns = [\n",
    "            f'{ticker} Close',\n",
    "            f'{ticker} daily move%',\n",
    "            f'{ticker} ST trend signal',\n",
    "            f'{ticker} cumulative change since signal',\n",
    "            f'{ticker} cumulative change 90-day breakthrough',\n",
    "            f'{ticker} Rolling Max Drawdown',\n",
    "            f'{ticker} Rolling Up Down Ratio',\n",
    "            f'{ticker} Rolling TSI',\n",
    "            f'{ticker} Rolling Volatility',\n",
    "            f'{ticker} Consecutive Up Days',\n",
    "            f'{ticker} Max Rolling Consecutive Up Days',\n",
    "            f'{ticker} Max_SemiAnnual_Consecutive_Up_Days',\n",
    "            f'{ticker} Potential_Up_Days',\n",
    "            f'{ticker} RSI',\n",
    "            f'{ticker} Momentum',\n",
    "            f'{ticker} ATR'\n",
    "        ]\n",
    "\n",
    "        # Check if Alpha and Beta exist in data for column addition\n",
    "        if 'Alpha' in data.columns:\n",
    "            trend_indicator[f'{ticker} Alpha'] = data['Alpha']\n",
    "            trend_columns.append(f'{ticker} Alpha')\n",
    "\n",
    "        if 'Beta' in data.columns:\n",
    "            trend_indicator[f'{ticker} Beta'] = data['Beta']\n",
    "            trend_columns.append(f'{ticker} Beta')\n",
    "\n",
    "        trend_indicator.columns = trend_columns\n",
    "        \n",
    "        # ** 15. Sortino Ratio Calculation Section **\n",
    "        average_return = data['Price_Change%'].rolling(window=rolling_window).mean()\n",
    "        downside_returns = data['Price_Change%'][data['Price_Change%'] < target_return].rolling(window=rolling_window)\n",
    "        downside_deviation = downside_returns.apply(lambda x: (x ** 2).mean() ** 0.5 if not x.empty else 0)\n",
    "        data['Sortino Ratio'] = (average_return - target_return) / downside_deviation\n",
    "        data['Sortino Ratio'].replace([float('inf'), -float('inf')], 0, inplace=True)  # Replace infinities\n",
    "\n",
    "        # ** 16. Calmar Ratio Calculation Section **\n",
    "        annualized_return = ((1 + average_return / 100) ** 252) - 1\n",
    "        data['Calmar Ratio'] = annualized_return / abs(data['Rolling_Drawdown'].min())  # Use current rolling drawdown\n",
    "\n",
    "        # ** 17. Sharpe Ratio Calculation Section **\n",
    "        trend_indicator[f'{ticker} Sortino Ratio'] = data['Sortino Ratio']\n",
    "        trend_indicator[f'{ticker} Calmar Ratio'] = data['Calmar Ratio']\n",
    "\n",
    "        results[ticker] = trend_indicator  # Store the results for this ticker\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "# ** Risk-Free Rate Calculation Section **\n",
    "if \"^TNX\" in results:  # Ensure ^TNX has been processed successfully\n",
    "    treasury_yield = results[\"^TNX\"]['^TNX Close']\n",
    "    risk_free_rate = treasury_yield / 100 / 252  # Convert from annual to daily\n",
    "else:\n",
    "    print(\"Warning: ^TNX results not found. Defaulting risk-free rate to 0.\")\n",
    "    risk_free_rate = 0.0  # Fallback risk-free rate\n",
    "\n",
    "# ** Calculate Sharpe Ratio for all tickers using the risk-free rate **\n",
    "for ticker in tickers:\n",
    "    if ticker in results:\n",
    "        data = results[ticker]\n",
    "        rolling_average_return = data[f'{ticker} daily move%'].rolling(window=rolling_window).mean()\n",
    "        rolling_std_dev_returns = data[f'{ticker} daily move%'].rolling(window=rolling_window).std()\n",
    "\n",
    "        # Define Sharpe Ratio; replace infinities for stability\n",
    "        data[f'{ticker} Sharpe Ratio'] = (rolling_average_return - risk_free_rate) / rolling_std_dev_returns\n",
    "        data[f'{ticker} Sharpe Ratio'].replace([float('inf'), -float('inf')], 0, inplace=True)  # Replace infinities\n",
    "        results[ticker] = data  # Update results with Sharpe Ratio\n",
    "\n",
    "# ** Display Results Section **\n",
    "# for ticker in tickers:\n",
    "#     if ticker in results:  # Only display results for tickers that were processed successfully\n",
    "#         print(f\"Results for {ticker}:\")\n",
    "#         display(results[ticker].tail(2))  # Display the last 10 entries\n",
    "\n",
    "# Get the indices where the daily move percentage is less than -2%\n",
    "high_move_indices = results['^IXIC'][results['^IXIC']['^IXIC daily move%'] < -2].index\n",
    "\n",
    "# Convert DatetimeIndex to a list of datetime objects\n",
    "date_list = high_move_indices.tolist()\n",
    "\n",
    "# Convert the dates to strings formatted as 'YYYY-MM-DD'\n",
    "date_list_as_strings = [date.strftime('%Y-%m-%d') for date in date_list]\n",
    "\n",
    "# Display the formatted list of dates\n",
    "print(\"List of dates with a daily move less than -2%:\", date_list_as_strings)\n",
    "\n",
    "# Iterate over each ticker in the results\n",
    "for ticker in results:\n",
    "    # Access the DataFrame for the current ticker\n",
    "    df = results[ticker]\n",
    "    \n",
    "    # Create a new column for the reversed_trend_flag, initially set to 0\n",
    "    df[f'{ticker} anti-drawdown flag'] = 0\n",
    "    \n",
    "    # Convert date_list_as_strings to datetime objects for comparison\n",
    "    date_list_as_datetimes = pd.to_datetime(date_list_as_strings)\n",
    "    \n",
    "    # Create a mask that checks for dates in date_list_as_datetimes\n",
    "    mask = df.index.isin(date_list_as_datetimes)\n",
    "    \n",
    "    # Set the reversed_trend_flag to 1 for those dates if daily move% > -0.5%\n",
    "    df.loc[mask, f'{ticker} anti-drawdown flag'] = (df.loc[mask, f'{ticker} daily move%'] > -0.5).astype(int)\n",
    "\n",
    "    # Update the results dictionary with the modified DataFrame\n",
    "    results[ticker] = df\n",
    "    \n",
    "    # mask = results['SFM'].index.isin(date_list_as_datetimes)\n",
    "    # filtered_df = results['SFM'][mask]\n",
    "    # filtered_df\n",
    "    \n",
    "    # Set your rolling window size\n",
    "    rolling_window_size = 180  # Adjust this as needed\n",
    "\n",
    "    # Calculate the rolling average of 'anti-drawdown flag' and create a new column\n",
    "    results[ticker][f'{ticker} Rolling Average Anti Drawdown'] = results[ticker][f'{ticker} anti-drawdown flag'].rolling(window=rolling_window_size).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirectory = 'data_outputs'  # This is your target subfolder\n",
    "file_name = 'technical_indicators_HMHQ.xlsx'\n",
    "file_path = os.path.join(current_directory, subdirectory, file_name)  # Full path for the file\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "    for ticker, df in results.items():\n",
    "        df.to_excel(writer, sheet_name=ticker)  # Save each ticker's DataFrame to a separate sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>daily move%</th>\n",
       "      <th>ST trend signal</th>\n",
       "      <th>cumulative change since signal</th>\n",
       "      <th>cumulative change 90-day breakthrough</th>\n",
       "      <th>Rolling Max Drawdown</th>\n",
       "      <th>Rolling Up Down Ratio</th>\n",
       "      <th>Rolling TSI</th>\n",
       "      <th>Rolling Volatility</th>\n",
       "      <th>...</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>ATR</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Sortino Ratio</th>\n",
       "      <th>Calmar Ratio</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>anti-drawdown flag</th>\n",
       "      <th>Rolling Average Anti Drawdown</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>11669.959961</td>\n",
       "      <td>-1.603277</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.115912</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.043510</td>\n",
       "      <td>1.158259</td>\n",
       "      <td>-17.937931</td>\n",
       "      <td>1.342291</td>\n",
       "      <td>...</td>\n",
       "      <td>162.889648</td>\n",
       "      <td>226.306982</td>\n",
       "      <td>0.079654</td>\n",
       "      <td>1.075255</td>\n",
       "      <td>0.058187</td>\n",
       "      <td>1.671294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>^IXIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>11787.400391</td>\n",
       "      <td>1.006348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.143553</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033885</td>\n",
       "      <td>1.186577</td>\n",
       "      <td>-14.299621</td>\n",
       "      <td>1.350886</td>\n",
       "      <td>...</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>230.623486</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>1.082886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.006795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>^IXIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>11823.959961</td>\n",
       "      <td>0.310158</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.310158</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.030888</td>\n",
       "      <td>1.465754</td>\n",
       "      <td>-12.516880</td>\n",
       "      <td>1.284620</td>\n",
       "      <td>...</td>\n",
       "      <td>429.019531</td>\n",
       "      <td>225.604980</td>\n",
       "      <td>0.192804</td>\n",
       "      <td>1.038756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.752010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>^IXIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>11768.839844</td>\n",
       "      <td>-0.466173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466173</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035406</td>\n",
       "      <td>1.315321</td>\n",
       "      <td>-9.823225</td>\n",
       "      <td>1.288319</td>\n",
       "      <td>...</td>\n",
       "      <td>301.859375</td>\n",
       "      <td>225.298486</td>\n",
       "      <td>0.137964</td>\n",
       "      <td>1.031187</td>\n",
       "      <td>0.101535</td>\n",
       "      <td>3.157224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>^IXIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-28</td>\n",
       "      <td>11716.080078</td>\n",
       "      <td>-0.448300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.912384</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039730</td>\n",
       "      <td>1.264906</td>\n",
       "      <td>-5.587731</td>\n",
       "      <td>1.294047</td>\n",
       "      <td>...</td>\n",
       "      <td>260.540039</td>\n",
       "      <td>226.346924</td>\n",
       "      <td>0.120463</td>\n",
       "      <td>1.036212</td>\n",
       "      <td>0.088501</td>\n",
       "      <td>2.695363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>^IXIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date         Close  daily move%  ST trend signal  \\\n",
       "0 2023-03-22  11669.959961    -1.603277              1.0   \n",
       "1 2023-03-23  11787.400391     1.006348              1.0   \n",
       "2 2023-03-24  11823.959961     0.310158             -1.0   \n",
       "3 2023-03-27  11768.839844    -0.466173              1.0   \n",
       "4 2023-03-28  11716.080078    -0.448300              1.0   \n",
       "\n",
       "   cumulative change since signal  cumulative change 90-day breakthrough  \\\n",
       "0                        2.115912                                      0   \n",
       "1                        3.143553                                      0   \n",
       "2                        0.310158                                      0   \n",
       "3                       -0.466173                                      0   \n",
       "4                       -0.912384                                      0   \n",
       "\n",
       "   Rolling Max Drawdown  Rolling Up Down Ratio  Rolling TSI  \\\n",
       "0             -0.043510               1.158259   -17.937931   \n",
       "1             -0.033885               1.186577   -14.299621   \n",
       "2             -0.030888               1.465754   -12.516880   \n",
       "3             -0.035406               1.315321    -9.823225   \n",
       "4             -0.039730               1.264906    -5.587731   \n",
       "\n",
       "   Rolling Volatility  ...    Momentum         ATR     Alpha      Beta  \\\n",
       "0            1.342291  ...  162.889648  226.306982  0.079654  1.075255   \n",
       "1            1.350886  ...  197.000000  230.623486  0.093911  1.082886   \n",
       "2            1.284620  ...  429.019531  225.604980  0.192804  1.038756   \n",
       "3            1.288319  ...  301.859375  225.298486  0.137964  1.031187   \n",
       "4            1.294047  ...  260.540039  226.346924  0.120463  1.036212   \n",
       "\n",
       "   Sortino Ratio  Calmar Ratio  Sharpe Ratio  anti-drawdown flag  \\\n",
       "0       0.058187      1.671294           NaN                   0   \n",
       "1            NaN      2.006795           NaN                   0   \n",
       "2            NaN      4.752010           NaN                   0   \n",
       "3       0.101535      3.157224           NaN                   0   \n",
       "4       0.088501      2.695363           NaN                   0   \n",
       "\n",
       "   Rolling Average Anti Drawdown  Ticker  \n",
       "0                            NaN   ^IXIC  \n",
       "1                            NaN   ^IXIC  \n",
       "2                            NaN   ^IXIC  \n",
       "3                            NaN   ^IXIC  \n",
       "4                            NaN   ^IXIC  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty list to store modified DataFrames\n",
    "modified_dfs = []\n",
    "\n",
    "# Iterate over all tickers and their corresponding DataFrames\n",
    "for ticker, df in results.items():\n",
    "    # Reset the index to make the date a column\n",
    "    df_reset = df.reset_index(drop=False)  # drop=False keeps the index\n",
    "\n",
    "    # Add a new column for the ticker\n",
    "    df_reset['Ticker'] = ticker\n",
    "\n",
    "    # Rename columns to remove the ticker string\n",
    "    # Assuming columns with ticker are structured like '{ticker} ColumnName'\n",
    "    df_reset.columns = [col.replace(f'{ticker} ', '') for col in df_reset.columns]\n",
    "    \n",
    "    # Drop the 'Trend signal' column if it exists    \n",
    "    if 'Strend signal' in df_reset.columns:        \n",
    "        df_reset.drop(columns=['Strend signal'], inplace=True)\n",
    "    \n",
    "    # Append the modified DataFrame to the list\n",
    "    modified_dfs.append(df_reset)\n",
    "\n",
    "# Combine all modified DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(modified_dfs, ignore_index=True)\n",
    "\n",
    "subdirectory = 'data_outputs'  # This is your target subfolder\n",
    "file_name = 'technical_indicators_HMHQ.csv'\n",
    "file_path = os.path.join(current_directory, subdirectory, file_name)  # Full path for the file\n",
    "\n",
    "# Now you can save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(file_path, index=False)\n",
    "\n",
    "# Print out the first few rows of the combined DataFrame\n",
    "display(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Initialize a dictionary to hold the correlations with target stock\n",
    "correlation_results = {}\n",
    "\n",
    "# List of relevant indicators for correlation analysis\n",
    "indicators = [\n",
    "    'ST trend signal',\n",
    "    'cumulative change since signal',\n",
    "    'cumulative change 90-day breakthrough',\n",
    "    'Rolling Max Drawdown',\n",
    "    'Rolling Average Anti Drawdown',\n",
    "    'Rolling Up Down Ratio',\n",
    "    'Rolling TSI',\n",
    "    'Rolling Volatility',\n",
    "    'Potential_Up_Days',\n",
    "    'Consecutive Up Days',\n",
    "    'Max Rolling Consecutive Up Days',\n",
    "    'RSI',\n",
    "    'Momentum',\n",
    "    'ATR',\n",
    "    'Alpha',\n",
    "    'Beta',\n",
    "    'Sortino Ratio',\n",
    "    'Calmar Ratio',\n",
    "    'Sharpe Ratio'\n",
    "]\n",
    "\n",
    "# Create a list of DataFrames for other tickers\n",
    "other_tickers_dfs = results\n",
    "\n",
    "# Calculate correlations for each indicator with AAPL\n",
    "for ticker, df_other in other_tickers_dfs.items():\n",
    "    correlations = {}\n",
    "    for indicator in indicators:\n",
    "        focus_col = f'SFM {indicator}'\n",
    "        other_col = f'{ticker} {indicator}'\n",
    "\n",
    "        # Ensure both columns exist before calculating\n",
    "        if focus_col in other_tickers_dfs['SFM'].columns and other_col in df_other.columns:\n",
    "            try:\n",
    "                correlation = other_tickers_dfs['SFM'][focus_col].corr(df_other[other_col])\n",
    "                correlations[indicator] = correlation\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating correlation for {ticker}: {str(e)}\")\n",
    "\n",
    "    # Calculate the ensemble correlation for the current ticker\n",
    "    if correlations:  # Check if any correlations were calculated\n",
    "        ensemble_correlation = np.mean(list(correlations.values()))\n",
    "        correlation_results[ticker] = ensemble_correlation\n",
    "\n",
    "# Convert the results dictionary into a DataFrame for better readability\n",
    "results_df = pd.DataFrame(correlation_results.items(), columns=['Ticker', 'Ensemble Correlation'])\n",
    "\n",
    "# Sort results_df by 'Ensemble Correlation' in descending order\n",
    "sorted_results_df = results_df.sort_values(by='Ensemble Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporting_Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Normalized Weighted Score</th>\n",
       "      <th>Simple Average Score</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>SFM</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>SMR</td>\n",
       "      <td>34.520711</td>\n",
       "      <td>0.207802</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>IDCC</td>\n",
       "      <td>31.580485</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>30.689850</td>\n",
       "      <td>0.179418</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>CL</td>\n",
       "      <td>29.352112</td>\n",
       "      <td>0.159810</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>AFRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>ESOA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>VNO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081316</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>RVMD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140718</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reporting_Date Ticker  Normalized Weighted Score  Simple Average Score  \\\n",
       "0      2024-11-08    SFM                 100.000000              1.000000   \n",
       "1      2024-11-08    SMR                  34.520711              0.207802   \n",
       "2      2024-11-08   IDCC                  31.580485              0.215100   \n",
       "3      2024-11-08   PHYS                  30.689850              0.179418   \n",
       "4      2024-11-08     CL                  29.352112              0.159810   \n",
       "..            ...    ...                        ...                   ...   \n",
       "62     2024-11-08   AFRM                        NaN             -0.016196   \n",
       "63     2024-11-08   ESOA                        NaN              0.064622   \n",
       "64     2024-11-08    VNO                        NaN              0.081316   \n",
       "65     2024-11-08   RVMD                        NaN              0.140718   \n",
       "66     2024-11-08     SE                        NaN              0.249458   \n",
       "\n",
       "    Ranking  \n",
       "0       1.0  \n",
       "1       2.0  \n",
       "2       3.0  \n",
       "3       4.0  \n",
       "4       5.0  \n",
       "..      ...  \n",
       "62      NaN  \n",
       "63      NaN  \n",
       "64      NaN  \n",
       "65      NaN  \n",
       "66      NaN  \n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subdirectory = 'data_outputs'  # This is your target subfolder\n",
    "file_name = 'HMHQ_score_ranking.csv'\n",
    "file_path = os.path.join(current_directory, subdirectory, file_name)  # Full path for the file\n",
    "\n",
    "sorted_normalized_results_df = pd.read_csv(file_path)\n",
    "display(sorted_normalized_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Normalized Weighted Scores with Simple Averages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporting_Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Normalized Weighted Score</th>\n",
       "      <th>Simple Average Score</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>SFM</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>SMR</td>\n",
       "      <td>32.028526</td>\n",
       "      <td>0.215882</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>IDCC</td>\n",
       "      <td>28.837406</td>\n",
       "      <td>0.219950</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>PHYS</td>\n",
       "      <td>27.096233</td>\n",
       "      <td>0.178551</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>COST</td>\n",
       "      <td>25.854927</td>\n",
       "      <td>0.165329</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reporting_Date Ticker  Normalized Weighted Score  Simple Average Score  \\\n",
       "33     2024-11-09    SFM                 100.000000              1.000000   \n",
       "49     2024-11-09    SMR                  32.028526              0.215882   \n",
       "50     2024-11-09   IDCC                  28.837406              0.219950   \n",
       "30     2024-11-09   PHYS                  27.096233              0.178551   \n",
       "27     2024-11-09   COST                  25.854927              0.165329   \n",
       "\n",
       "    Ranking  \n",
       "33      1.0  \n",
       "49      2.0  \n",
       "50      3.0  \n",
       "30      4.0  \n",
       "27      5.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a dictionary to hold the correlations with the target stock\n",
    "correlation_results = {}\n",
    "\n",
    "# List of relevant indicators for correlation analysis\n",
    "indicators = [\n",
    "    'ST trend signal',\n",
    "    'cumulative change since signal',\n",
    "    'cumulative change 90-day breakthrough',\n",
    "    'Rolling Max Drawdown',\n",
    "    'Rolling Average Anti Drawdown',\n",
    "    'Rolling Up Down Ratio',\n",
    "    'Rolling TSI',\n",
    "    'Rolling Volatility',\n",
    "    'Potential_Up_Days',\n",
    "    'Consecutive Up Days',\n",
    "    'Max Rolling Consecutive Up Days',\n",
    "    'RSI',\n",
    "    'Momentum',\n",
    "    'ATR',\n",
    "    'Alpha',\n",
    "    'Beta',\n",
    "    'Sortino Ratio',\n",
    "    'Calmar Ratio',\n",
    "    'Sharpe Ratio'\n",
    "]\n",
    "\n",
    "# Define relative weights for each indicator\n",
    "weights = [\n",
    "    5,    # Weight for 'ST trend signal'\n",
    "    15,   # Weight for 'cumulative change since signal'\n",
    "    15,    # Weight for 'cumulative change 90-day breakthrough'\n",
    "    15,   # Weight for 'Rolling Max Drawdown'\n",
    "    15,   # Weight for 'Rolling Average Anti Drawdown'\n",
    "    20,   # Weight for 'Rolling Up Down Ratio'\n",
    "    10,   # Weight for 'Rolling TSI'\n",
    "    5,    # Weight for 'Rolling Volatility'\n",
    "    15,   # Weight for 'Potential_Up_Days'\n",
    "    5,    # Weight for 'Consecutive Up Days'\n",
    "    10,   # Weight for 'Max Rolling Consecutive Up Days'\n",
    "    20,   # Weight for 'RSI'\n",
    "    15,   # Weight for 'Momentum'\n",
    "    5,    # Weight for 'ATR'\n",
    "    5,    # Weight for 'Alpha'\n",
    "    5,    # Weight for 'Beta'\n",
    "    15,   # Weight for 'Sortino Ratio'\n",
    "    15,   # Weight for 'Calmar Ratio'\n",
    "    15    # Weight for 'Sharpe Ratio'\n",
    "]\n",
    "\n",
    "# Create a list of DataFrames for other tickers\n",
    "other_tickers_dfs = results\n",
    "\n",
    "# Calculate correlations for each indicator with SFM\n",
    "for ticker, df_other in other_tickers_dfs.items():\n",
    "    correlations = {}\n",
    "    for indicator in indicators:\n",
    "        focus_col = f'SFM {indicator}'\n",
    "        other_col = f'{ticker} {indicator}'\n",
    "\n",
    "        # Ensure both columns exist before calculating\n",
    "        if focus_col in other_tickers_dfs['SFM'].columns and other_col in df_other.columns:\n",
    "            try:\n",
    "                correlation = other_tickers_dfs['SFM'][focus_col].corr(df_other[other_col])\n",
    "                correlations[indicator] = correlation\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating correlation for {ticker} using {indicator}: {str(e)}\")\n",
    "\n",
    "    # Calculate the weighted ensemble correlation for the current ticker\n",
    "    if correlations:  # Check if any correlations were calculated\n",
    "        weighted_sum = sum(correlations[indicator] * weights[i] for i, indicator in enumerate(indicators) if indicator in correlations)\n",
    "        correlation_results[ticker] = {\"weighted_sum\": weighted_sum, \"correlations\": correlations}\n",
    "    else:\n",
    "        print(f\"No valid correlations calculated for {ticker}\")\n",
    "\n",
    "# Debug: Print correlation_results to check for NaN values\n",
    "# print(\"Correlation Results:\", correlation_results)\n",
    "\n",
    "# After all results are calculated, determine the min and max of the weighted sums\n",
    "if correlation_results:\n",
    "    valid_sums = [v[\"weighted_sum\"] for v in correlation_results.values() if pd.notna(v[\"weighted_sum\"])]\n",
    "\n",
    "    min_weighted_sum = min(valid_sums) if valid_sums else 0\n",
    "    max_weighted_sum = max(valid_sums) if valid_sums else 100  # To avoid max equal to min\n",
    "\n",
    "    # Normalizing the weighted sums to a range of 0 to 100\n",
    "    normalized_results = {}\n",
    "    simple_averages = {}\n",
    "\n",
    "    for ticker, result in correlation_results.items():\n",
    "        weighted_sum = result[\"weighted_sum\"]\n",
    "        correlations = result[\"correlations\"]\n",
    "\n",
    "        # Calculate simple average only of valid correlations\n",
    "        valid_correlations = [v for v in correlations.values() if pd.notna(v)]\n",
    "        simple_average = sum(valid_correlations) / len(valid_correlations) if valid_correlations else 0\n",
    "        \n",
    "        # Normalize the weighted sum\n",
    "        normalized_score = ((weighted_sum - min_weighted_sum) / (max_weighted_sum - min_weighted_sum) * 100) if max_weighted_sum > min_weighted_sum else 0\n",
    "\n",
    "        normalized_results[ticker] = normalized_score\n",
    "        simple_averages[ticker] = simple_average\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Reporting_Date': datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    'Ticker': normalized_results.keys(),\n",
    "    'Normalized Weighted Score': normalized_results.values(),\n",
    "    'Simple Average Score': simple_averages.values()\n",
    "})\n",
    "\n",
    "# Sort results_df by 'Normalized Weighted Score' in descending order\n",
    "sorted_normalized_results_df = results_df.sort_values(by='Normalized Weighted Score', ascending=False)\n",
    "sorted_normalized_results_df['Ranking'] = sorted_normalized_results_df['Normalized Weighted Score'].rank(method='min', ascending=False)\n",
    "\n",
    "# Display the sorted results\n",
    "print(\"Sorted Normalized Weighted Scores with Simple Averages:\")\n",
    "display(sorted_normalized_results_df[:5])\n",
    "\n",
    "sorted_normalized_results_df.to_csv(file_path, mode = 'w', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
